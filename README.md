<h1 align="center">Machine Learning Algorithms</h1>
<h3 align="center">🚀 Implementations of Classic Machine Learning Algorithms</h3>

<p align="center">
  <img src="https://img.shields.io/github/languages/top/OT1devl/Machine-Learning-Algorithms?style=flat" alt="Languages" />
  <img src="https://img.shields.io/github/license/OT1devl/Machine-Learning-Algorithms?style=flat" alt="License" />
  <img src="https://img.shields.io/github/last-commit/OT1devl/Machine-Learning-Algorithms?style=flat" alt="Last Commit" />
</p>

---

### 📜 **About the Repository**
This repository contains implementations of various classic machine learning algorithms from scratch, written using only Python and NumPy. The goal is to help users understand the underlying mechanics of machine learning models and gain insight into their workings without relying on high-level libraries.

---

### ⚡ **Implemented Algorithms**
- Linear Regression
- Logistic Regression
- K-Nearest Neighbors (KNN)
- Support Vector Machines (SVM)
- Decision Trees
- Naive Bayes
- K-Means Clustering
- Principal Component Analysis (PCA)
- And more...

---

### 🛠️ **Technologies Used**
- **Python**
- **NumPy**
- **Matplotlib** (for visualizations)

---

### 📂 **Main Directories and Files**
- **linear_regression.py**: Implementation of the Linear Regression algorithm.
- **logistic_regression.py**: Implementation of Logistic Regression for classification tasks.
- **knn.py**: K-Nearest Neighbors algorithm, both for classification and regression.
- **svm.py**: Implementation of Support Vector Machines for classification tasks.
- **decision_tree.py**: A decision tree classifier for supervised learning.
- **naive_bayes.py**: A basic implementation of the Naive Bayes algorithm.
- **kmeans.py**: K-Means Clustering algorithm for unsupervised learning.
- **pca.py**: Principal Component Analysis (PCA) for dimensionality reduction.
- **visualizations/**: Directory containing visualizations of model outputs and results.

---

### 🚀 **Future Improvements**
- Additional advanced algorithms like Random Forests, XGBoost, etc.
- Integration of performance metrics for each model (e.g., accuracy, precision, recall, F1 score).
- Enhanced visualization tools to demonstrate model learning over time.
- Add support for more complex datasets and larger-scale experiments.

---

### 📊 **Statistics**
<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=OT1devl&show_icons=true&theme=radical" width="49%" />
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=OT1devl&theme=radical" width="49%" />
</p>

---

### 🚀 **Contact**
📧 **Email:** *[otidevv1@gmail.com]* 
